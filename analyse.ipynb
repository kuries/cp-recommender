{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CP Recommendation System\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content Based filtering\n",
    "\n",
    "First let's start with content based filtering\n",
    "Here, we'll be concatenating the tags into a single string and run cosine similarity based on text to find the similarity between this particular problem and other problems\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contestId       0\n",
      "index           0\n",
      "name            0\n",
      "type            0\n",
      "rating        176\n",
      "tags            0\n",
      "points       2251\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#importing stuff\n",
    "import requests\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "import pandas as pd\n",
    "\n",
    "#load data\n",
    "tag_set = set()\n",
    "data = requests.get(\"https://codeforces.com/api/problemset.problems\").json()\n",
    "problems_json = data[\"result\"][\"problems\"]\n",
    "\n",
    "problems = json_normalize(problems_json)\n",
    "print(problems.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, one of the columns has the name index which is overriding the original column \"index\", so let's rename it to something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "contestId       0\n",
      "ID              0\n",
      "name            0\n",
      "type            0\n",
      "rating        186\n",
      "tags            0\n",
      "points       2195\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "column_list = list(problems.columns)\n",
    "column_list[1] = \"ID\"\n",
    "problems.columns = column_list\n",
    "print(problems.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Data From Users\n",
    "\n",
    "Time to get the user dataset, we'll collect the data of all users who participated in atleast one contest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      contestId ID                    name         type  points  rating  \\\n",
      "0          1602  B            Divine Array  PROGRAMMING  1000.0  1100.0   \n",
      "1          1602  A        Two Subsequences  PROGRAMMING   500.0   800.0   \n",
      "2          1601  F               Two Sorts  PROGRAMMING  3000.0  3400.0   \n",
      "3          1601  E          Phys Ed Online  PROGRAMMING  2250.0  2900.0   \n",
      "4          1601  D      Difficult Mountain  PROGRAMMING  2250.0  2700.0   \n",
      "...         ... ..                     ...          ...     ...     ...   \n",
      "7320          2  B     The least round way  PROGRAMMING     NaN  2000.0   \n",
      "7321          2  A                  Winner  PROGRAMMING     NaN  1500.0   \n",
      "7322          1  C  Ancient Berland Circus  PROGRAMMING     NaN  2100.0   \n",
      "7323          1  B             Spreadsheet  PROGRAMMING     NaN  1600.0   \n",
      "7324          1  A          Theatre Square  PROGRAMMING     NaN  1000.0   \n",
      "\n",
      "                                                   tags  \n",
      "0             [constructive algorithms, implementation]  \n",
      "1                                      [implementation]  \n",
      "2     [binary search, dfs and similar, math, meet-in...  \n",
      "3            [brute force, data structures, dp, greedy]  \n",
      "4               [data structures, dp, greedy, sortings]  \n",
      "...                                                 ...  \n",
      "7320                                         [dp, math]  \n",
      "7321                          [hashing, implementation]  \n",
      "7322                                   [geometry, math]  \n",
      "7323                             [implementation, math]  \n",
      "7324                                             [math]  \n",
      "\n",
      "[7325 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "print(problems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_users():\n",
    "    user_url = \"https://codeforces.com/api/user.ratedList\"\n",
    "    user_data = requests.get(user_url).json()\n",
    "\n",
    "    user_data = user_data[\"result\"]\n",
    "\n",
    "    df = json_normalize(user_data)\n",
    "    return df\n",
    "\n",
    "def get_users_from_csv():\n",
    "    df = pd.read_csv(\"data/df_user.csv\", encoding='utf-8')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code gets the submissions of one particular user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_submissions(handle):\n",
    "    start, count = (1, 999)\n",
    "\n",
    "    user_url = \"https://codeforces.com/api/user.status?handle={}&from={}&count={}\"\n",
    "    user_url = user_url.format(handle, start, count)\n",
    "    user_data = requests.get(user_url).json()\n",
    "\n",
    "    submissions = user_data[\"result\"]\n",
    "    df = json_normalize(submissions)\n",
    "    #print(df[df[\"verdict\"] == \"OK\"][\"problem.name\"] )\n",
    "    return df\n",
    "\n",
    "#df_submission = get_user_submissions(\"infnite_coder\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets remove the users based on the following conditions\n",
    " - have rating less than or equal to 0\n",
    " - have stayed inactive for more than 1 year.\n",
    "\n",
    " ### Note: Run this below cell only if there is no csv file present, otherwise skip to the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, date, timedelta\n",
    "\n",
    "df_user = get_users()\n",
    "\n",
    "df_user = df_user[['handle', 'country', 'rank', 'rating', 'maxRating', 'lastOnlineTimeSeconds']][df_user['rating']>0]\n",
    "\n",
    "now = datetime.now()\n",
    "lastYear = now.replace(year=now.year-1)\n",
    "\n",
    "df_user[\"lastOnline\"] = df_user['lastOnlineTimeSeconds'].map(lambda x: datetime.fromtimestamp(x))\n",
    "\n",
    "df_user = df_user[df_user['lastOnline']  > lastYear][df_user.columns.difference(['lastOnlineTimeSeconds'], sort=False)]\n",
    "\n",
    "df_user.to_csv(\"data/df_user.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this cell to load values into a dataframe from csv\n",
    "### Note: Run this cell if you already have a df_user.csv with values stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              handle        country                   rank  rating  maxRating  \\\n",
      "0            tourist        Belarus  legendary grandmaster    3707       3822   \n",
      "1  Retired_MiFaFaOvO          Samoa  legendary grandmaster    3681       3681   \n",
      "2               Benq  United States  legendary grandmaster    3672       3797   \n",
      "3          Radewoosh         Poland  legendary grandmaster    3627       3720   \n",
      "4             ksun48         Canada  legendary grandmaster    3547       3654   \n",
      "\n",
      "            lastOnline  \n",
      "0  2021-10-04 16:53:18  \n",
      "1  2021-10-04 09:58:05  \n",
      "2  2021-10-04 17:16:26  \n",
      "3  2021-10-04 00:38:52  \n",
      "4  2021-10-04 09:39:55  \n"
     ]
    }
   ],
   "source": [
    "df_user_total = get_users_from_csv()\n",
    "print(df_user_total.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_incorrect_user_submission(handle):\n",
    "    user_submission = get_user_submissions(handle)\n",
    "    return user_submission[user_submission[\"verdict\"] != \"OK\"][\"problem.name\"].head()\n",
    "\n",
    "def get_user_interactions(handle):\n",
    "    user_submission = get_user_submissions(handle)\n",
    "    if(len(user_submission.index) == 0):\n",
    "        return\n",
    "    problem_list = user_submission[user_submission[\"verdict\"] != \"OK\"][\"problem.name\"].unique()\n",
    "    for item in problem_list:\n",
    "        yield [handle, item, 1]\n",
    "\n",
    "def list_of_user_interactions():\n",
    "    combined_list = []\n",
    "    for user in df_user['handle']:\n",
    "        for gen_item in get_user_interactions(user):\n",
    "            combined_list.append(gen_item)\n",
    "    return combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols=['handle', 'problem_name', 'wrong_submission']\n",
    "user_problem_interaction = pd.DataFrame(columns=cols)\n",
    "\n",
    "for user in df_user['handle']:\n",
    "    incorrect_user_submission = get_incorrect_user_submission(user)\n",
    "\n",
    "    problem_freq = dict()\n",
    "    for item in incorrect_user_submission:\n",
    "        if item in problem_freq.keys():\n",
    "            problem_freq[item] = problem_freq[item]+1\n",
    "        else:\n",
    "            problem_freq[item] = 1\n",
    "    \n",
    "    for item in problem_freq:\n",
    "        new_row = [user, item, problem_freq[item]]\n",
    "        df_new_row = pd.DataFrame([new_row], columns=cols)\n",
    "        user_problem_interaction = pd.concat([user_problem_interaction, df_new_row])\n",
    "        #user_problem_interaction.append({'handle': user, 'problem_name': item, 'wrong_submission': problem_freq[item]}, ignore_index=True)\n",
    "\n",
    "user_problem_interaction = user_problem_interaction.reset_index(drop=True)\n",
    "user_problem_interaction.to_csv(\"data/user_problem_interaction.csv\", index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine Similarity\n",
    "Now we are gonna start our project with content based filtering with cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def combine_features(row):\n",
    "    return row[\"type\"]+\" \"+ \" \".join(row[\"tags\"])\n",
    "\n",
    "problems[\"combined_features\"] = problems.apply(combine_features, axis=1)\n",
    "\n",
    "count_matrix = CountVectorizer().fit_transform(problems[\"combined_features\"])\n",
    "cosine_sim = cosine_similarity(count_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_from_name(name):\n",
    "    return problems[problems.name == name].index\n",
    "\n",
    "problem_name = \"Armchairs\"\n",
    "index_of_prob = index_from_name(problem_name).values[0]\n",
    "tgs = problems.iloc[index_of_prob].tags\n",
    "\n",
    "# print(problems[problems[\"tags\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_user = pd.read_csv(\"data/df_user_random.csv\", encoding='utf-8')\n",
    "\n",
    "def batch_list_of_user_interactions():\n",
    "    combined_list = []\n",
    "    for user in df_user.iloc[999:1000]['handle']:\n",
    "        for gen_item in get_user_interactions(user):\n",
    "            combined_list.append(gen_item)\n",
    "    return combined_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_user_interaction = pd.DataFrame(list_of_user_interactions(), columns=['handle', 'problem', 'rating'])\n",
    "# print(len(df_user_interaction))\n",
    "combined_list = batch_list_of_user_interactions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interaction_list = pd.DataFrame(combined_list, columns=['handle', 'problem', 'rating'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# START FROM HERE\n",
    "### NCF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "interaction_list = pd.read_csv(\"data/df_user_interaction-02.csv\", encoding='utf-8')\n",
    "\n",
    "num_handle = interaction_list['handle']\n",
    "num_handle = pd.factorize(num_handle)[0]\n",
    "\n",
    "num_problem = interaction_list['problem']\n",
    "num_problem = pd.factorize(num_problem)[0]\n",
    "\n",
    "interaction_list['handle'] = num_handle\n",
    "interaction_list['problem'] = num_problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Skip this one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "all_problem_ids = interaction_list['problem'].unique()\n",
    "user_item_set = set(zip(interaction_list['handle'][1:10], interaction_list['problem'][1:10]))\n",
    "\n",
    "handles, problems, ratings = [], [], []\n",
    "\n",
    "num_negatives = 4\n",
    "\n",
    "for (user, problem) in user_item_set:\n",
    "    handles.append(user)\n",
    "    problems.append(problem)\n",
    "    ratings.append(1)\n",
    "    for _ in range(num_negatives):\n",
    "        negative_problem = np.random.choice(all_problem_ids)\n",
    "        while (user, negative_problem) in user_item_set:\n",
    "            negative_problem = np.random.choice(all_problem_ids)\n",
    "        handles.append(user)\n",
    "        problems.append(negative_problem)\n",
    "        ratings.append(0)\n",
    "        \n",
    "print(handles)\n",
    "print(problems)\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class recommender_data_set(Dataset):\n",
    "    def __init__(self, interaction_list, all_problem_ids):\n",
    "        self.handles, self.problems, self.rating = self.get_dataset(interaction_list, all_problem_ids)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.handles)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.handles[idx], self.problems[idx], self.rating[idx]\n",
    "    \n",
    "    def get_dataset(self, interaction_list, all_problem_ids):\n",
    "        handles, problems, rating = [], [], []\n",
    "        user_item_set = set(zip(interaction_list['handle'], interaction_list['problem']))\n",
    "        \n",
    "        num_negatives = 4\n",
    "\n",
    "        for (user, item) in user_item_set:\n",
    "            handles.append(user)\n",
    "            problems.append(item)\n",
    "            rating.append(1)\n",
    "            for _ in range(num_negatives):\n",
    "                negative_problem = np.random.choice(all_problem_ids)\n",
    "                while (user, negative_problem) in user_item_set:\n",
    "                    negative_problem = np.random.choice(all_problem_ids)\n",
    "                handles.append(user)\n",
    "                problems.append(negative_problem)\n",
    "                rating.append(0)\n",
    "        \n",
    "        return torch.tensor(handles), torch.tensor(problems), torch.tensor(rating)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import pytorch_lightning as pl\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class NCF(pl.LightningModule):\n",
    "    def __init__(self, num_handles, num_problems, interaction_list, all_problem_ids):\n",
    "        super().__init__()\n",
    "        self.handle_embedding = nn.Embedding(num_embeddings=num_handles, embedding_dim=8)\n",
    "        self.problem_embedding = nn.Embedding(num_embeddings=num_problems, embedding_dim=8)\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features=16, out_features=64)\n",
    "        self.fc2 = nn.Linear(in_features=64, out_features=32)\n",
    "        \n",
    "        self.output = nn.Linear(in_features=32, out_features=1)\n",
    "        \n",
    "        self.interaction_list = interaction_list\n",
    "        \n",
    "        self.all_problem_ids = all_problem_ids\n",
    "        \n",
    "    def forward(self, handle_input, problem_input):\n",
    "        handle_embedded = self.handle_embedding(handle_input)\n",
    "        problem_embedded = self.problem_embedding(problem_input)\n",
    "        \n",
    "        vector = torch.cat([handle_embedded, problem_embedded], dim=-1)\n",
    "        \n",
    "        vector = nn.ReLU()(self.fc1(vector))\n",
    "        vector = nn.ReLU()(self.fc2(vector))\n",
    "        \n",
    "        pred = nn.Sigmoid()(self.output(vector))\n",
    "        \n",
    "        return pred\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        handle_input, problem_input, rating = batch\n",
    "        predicted_labels = self(handle_input, problem_input)\n",
    "        loss = nn.BCELoss()(predicted_labels, rating.view(-1, 1).float())\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters())\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(recommender_data_set(self.interaction_list, self.all_problem_ids),batch_size=512, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_handles = interaction_list['handle'].max()+1\n",
    "num_problems = interaction_list['problem'].max()+1\n",
    "all_problem_ids = interaction_list['problem'].unique()\n",
    "\n",
    "model = NCF(num_handles, num_problems, interaction_list, all_problem_ids)\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=5, gpus=0, reload_dataloaders_every_epoch=True, progress_bar_refresh_rate=50, logger=False, checkpoint_callback=False)\n",
    "\n",
    "trainer.fit(model)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "90f813e45ffbc6032975d51568b4e3652c90798aae0741a6c44bb16ed2e63418"
  },
  "kernelspec": {
   "display_name": "Python 3.9.1 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
